#!/bin/bash

########
#
# Copyright © 2014-2019 Florian Pritz <bluewind@xinu.at>
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, see http://www.gnu.org/licenses/.
#
########
#
# This is a simple mirroring script. To save bandwidth it first checks a
# timestamp via HTTP and only runs rsync when the timestamp differs from the
# local copy. As of 2016, a single rsync run without changes transfers roughly
# 6MiB of data which adds up to roughly 250GiB of traffic per month when rsync
# is run every minute. Performing a simple check via HTTP first can thus save a
# lot of traffic.

# Directory where the repo is stored locally. Example: /srv/repo
target="/home/$USER/arch-mirror-repo"

# Lockfile path
lock="$target/syncrepo.lck"

# If you want to limit the bandwidth used by rsync set this.
# Use 0 to disable the limit.
# The default unit is KiB (see man rsync /--bwlimit for more)
bwlimit=0

# mirrors=(
# "rsync://repository.su/archlinux"
# "rsync://mirrors.powernet.com.ru/pub/archlinux"
# "rsync://mirror.truenetwork.ru/archlinux"
# "rsync://mirror2.sl-chat.ru/archlinux"
# "rsync://mirror3.sl-chat.ru/archlinux"
# "rsync://mirror.nw-sys.ru/archlinux"
# )

# Получаем зеркала из /etc/pacman.d/mirrorlist
mirrorlist_file="/etc/pacman.d/mirrorlist"
mirrors=()

if [[ -f "$mirrorlist_file" ]]; then
  while IFS= read -r line; do
    if [[ "$line" == "Server = "* ]]; then
      # Извлекаем URL
      url="${line#Server = }"
      # Преобразуем https:// в rsync://
      rsync_url="${url/https:\/\//rsync:\/\/}"
      # Удаляем /$repo/os/$arch
      rsync_url="${rsync_url/\/\$repo\/os\/\$arch/}"
      mirrors+=("$rsync_url")
    fi
  done < "$mirrorlist_file"
else
  echo "Файл $mirrorlist_file не найден. Используются зеркала по умолчанию (если они были заданы ранее)." >&2
fi

for m in "${mirrors[@]}"; do
  if rsync --list-only --timeout=5 --contimeout=5 "$m" "$target" &>/dev/null; then
    source_url="$m"
    break
  fi
done

if [[ -z "$source_url" ]]; then
  echo "No mirror reachable" >&2
  exit 1
fi

# HTTP‑URL для lastupdate: тот же хост по HTTPS + /lastupdate
lastupdate_url="${source_url/rsync:\/\/\//https:\/\/}/lastupdate"

#### END CONFIG

[ ! -d "${target}" ] && mkdir -p "${target}"

exec 9>"${lock}"
flock -n 9 || exit 1

# Cleanup any temporary files from old run that might remain.
# Note: You can skip this if you have rsync newer than 3.2.3
# not affected by https://github.com/WayneD/rsync/issues/192
find "${target}" -name '.~~tmp~~' -exec rm -r {} +

rsync_cmd() {
  local -a cmd=(rsync -rlptH --safe-links --delete-delay --delay-updates
    "--timeout=600" "--contimeout=60" --no-motd)

  if stty &>/dev/null; then
    cmd+=(-h -v --progress)
  else
    cmd+=(--quiet)
  fi

  if ((bwlimit>0)); then
    cmd+=("--bwlimit=$bwlimit")
  fi

  "${cmd[@]}" "$@"
}

# if we are called without a tty (cronjob) only run when there are changes
if ! tty -s && [[ -f "$target/lastupdate" ]] && \
   diff -b <(curl -Ls "$lastupdate_url") "$target/lastupdate" >/dev/null; then
  # keep lastsync file in sync for statistics generated by the Arch Linux website
  rsync_cmd "$source_url/lastsync" "$target/lastsync"
  exit 0
fi

rsync_cmd \
  --exclude='gnome-unstable' \
  --exclude='multilib-testing' \
  --exclude='core-testing' \
  --exclude='multilib-staging' \
  --exclude='extra-staging' \
  --exclude='core-staging' \
  --exclude='extra-testing' \
  "${source_url}" \
  "${target}"

curl -Ls "$lastupdate_url" > "${target}/lastupdate"

#echo "Last sync was $(date -d @$(cat ${target}/lastsync))"



###### NEW #########
# ===== Автоматическая индексация локальных репозиториев =====
# Для core-local, extra-local, community-local, multilib-local

# Определяем архитектуру
arch=$(uname -m)

# Перебираем только те репозитории, что существуют в каталоге
for repo in core extra community multilib; do
  repo_dir="$target/$repo/os/$arch"
  db_name="${repo}-local.db.tar.gz"
  db_path="$repo_dir/$db_name"
  state_file="$repo_dir/${repo}-local.state" # Файл для хранения хэша состояния пакетов

  # Пропускаем, если каталога нет
  [[ ! -d "$repo_dir" ]] && continue

  # Собираем информацию о текущих .pkg.tar.zst файлах (имя, размер, время модификации)
  # и вычисляем хэш этого состояния.
  current_pkg_files_details=""
  # Проверяем, есть ли пакеты, чтобы find не выдавал ошибку в пустом каталоге при использовании -printf
  if compgen -G "$repo_dir/*.pkg.tar.zst" > /dev/null; then
      current_pkg_files_details=$(find "$repo_dir" -maxdepth 1 -name '*.pkg.tar.zst' -printf '%f\t%s\t%T@\n' | sort)
  fi
  current_pkg_state_hash=$(echo -n "$current_pkg_files_details" | sha256sum | awk '{print $1}')

  old_pkg_state_hash=""
  if [[ -f "$state_file" ]]; then
    old_pkg_state_hash=$(cat "$state_file")
  fi

  if [[ "$current_pkg_state_hash" != "$old_pkg_state_hash" ]]; then
    echo "Обнаружены изменения для $repo-local в $repo_dir (или отсутствует файл состояния). Запуск индексации..."

    # Генерируем/обновляем базу
    if repo-add "$db_path" "$repo_dir"/*.pkg.tar.zst; then
      # Сохраняем новый хэш состояния после успешной индексации
      echo "$current_pkg_state_hash" > "$state_file"
      echo "Индексация $repo-local успешно завершена, файл состояния обновлен."
    else
      echo "Ошибка во время выполнения repo-add для $repo-local. Файл состояния не обновлен." >&2
      # Можно добавить удаление файла состояния, чтобы гарантировать повторную попытку при следующем запуске
      # rm -f "$state_file"
    fi
  else
    echo "Изменений для $repo-local в $repo_dir не обнаружено. Пропуск индексации."
  fi
done
