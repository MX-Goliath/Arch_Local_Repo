#!/bin/bash

########
#
# Copyright © 2014-2019 Florian Pritz <bluewind@xinu.at>
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, see http://www.gnu.org/licenses/.
#
########
#
# This is a simple mirroring script. To save bandwidth it first checks a
# timestamp via HTTP and only runs rsync when the timestamp differs from the
# local copy. As of 2016, a single rsync run without changes transfers roughly
# 6MiB of data which adds up to roughly 250GiB of traffic per month when rsync
# is run every minute. Performing a simple check via HTTP first can thus save a
# lot of traffic.

# Directory where the repo is stored locally. Example: /srv/repo
target="/home/$USER/arch-mirror-repo"

# Lockfile path
lock="$target/syncrepo.lck"

# If you want to limit the bandwidth used by rsync set this.
# Use 0 to disable the limit.
# The default unit is KiB (see man rsync /--bwlimit for more)
bwlimit=0

# mirrors=(
# "rsync://repository.su/archlinux"
# "rsync://mirrors.powernet.com.ru/pub/archlinux"
# "rsync://mirror.truenetwork.ru/archlinux"
# "rsync://mirror2.sl-chat.ru/archlinux"
# "rsync://mirror3.sl-chat.ru/archlinux"
# "rsync://mirror.nw-sys.ru/archlinux"
# )

# Получаем зеркала из /etc/pacman.d/mirrorlist
mirrorlist_file="/etc/pacman.d/mirrorlist"
mirrors=()

if [[ -f "$mirrorlist_file" ]]; then
  while IFS= read -r line; do
    if [[ "$line" == "Server = "* ]]; then
      # Извлекаем URL
      url="${line#Server = }"
      # Преобразуем https:// в rsync://
      rsync_url="${url/https:\/\//rsync:\/\/}"
      # Удаляем /$repo/os/$arch
      rsync_url="${rsync_url/\/\$repo\/os\/\$arch/}"
      mirrors+=("$rsync_url")
    fi
  done < "$mirrorlist_file"
else
  echo "Файл $mirrorlist_file не найден. Используются зеркала по умолчанию (если они были заданы ранее)." >&2
fi

for m in "${mirrors[@]}"; do
  if rsync --list-only --timeout=5 --contimeout=5 "$m" "$target" &>/dev/null; then
    source_url="$m"
    break
  fi
done

if [[ -z "$source_url" ]]; then
  echo "No mirror reachable" >&2
  exit 1
fi

# HTTP‑URL для lastupdate: тот же хост по HTTPS + /lastupdate
lastupdate_url="${source_url/rsync:\/\/\//https:\/\/}/lastupdate"

#### END CONFIG

[ ! -d "${target}" ] && mkdir -p "${target}"

exec 9>"${lock}"
flock -n 9 || exit 1

# Cleanup any temporary files from old run that might remain.
# Note: You can skip this if you have rsync newer than 3.2.3
# not affected by https://github.com/WayneD/rsync/issues/192
find "${target}" -name '.~~tmp~~' -exec rm -r {} +

rsync_cmd() {
  local -a cmd=(rsync -rlptH --safe-links --delete-delay --delay-updates
    "--timeout=600" "--contimeout=60" --no-motd)

  if stty &>/dev/null; then
    cmd+=(-h -v --progress)
  else
    cmd+=(--quiet)
  fi

  if ((bwlimit>0)); then
    cmd+=("--bwlimit=$bwlimit")
  fi

  "${cmd[@]}" "$@"
}

# if we are called without a tty (cronjob) only run when there are changes
if ! tty -s && [[ -f "$target/lastupdate" ]] && \
   diff -b <(curl -Ls "$lastupdate_url") "$target/lastupdate" >/dev/null; then
  # keep lastsync file in sync for statistics generated by the Arch Linux website
  rsync_cmd "$source_url/lastsync" "$target/lastsync"
  exit 0
fi

rsync_cmd \
  --exclude='gnome-unstable' \
  --exclude='multilib-testing' \
  --exclude='core-testing' \
  --exclude='multilib-staging' \
  --exclude='extra-staging' \
  --exclude='core-staging' \
  --exclude='extra-testing' \
  "${source_url}" \
  "${target}"

curl -Ls "$lastupdate_url" > "${target}/lastupdate"

#echo "Last sync was $(date -d @$(cat ${target}/lastsync))"



###### NEW #########
# ===== Автоматическая индексация локальных репозиториев =====
# Для core-local, extra-local, community-local, multilib-local

# Определяем архитектуру
arch=$(uname -m)

# Перебираем только те репозитории, что существуют в каталоге
for repo in core extra community multilib; do
  repo_dir="$target/$repo/os/$arch"
  db_name="${repo}-local.db.tar.gz"
  db_path="$repo_dir/$db_name"
  state_file="$repo_dir/${repo}-local.state" # Файл для хранения детального состояния пакетов

  # Пропускаем, если каталога нет
  [[ ! -d "$repo_dir" ]] && continue

  # Собираем информацию о текущих .pkg.tar.zst файлах
  current_pkg_files_details=""
  if compgen -G "$repo_dir/*.pkg.tar.zst" > /dev/null; then
      current_pkg_files_details=$(find "$repo_dir" -maxdepth 1 -name '*.pkg.tar.zst' -printf '%f\t%s\t%Ts\n' | sort)
  fi

  # Читаем предыдущее состояние
  old_pkg_files_details=""
  if [[ -f "$state_file" ]]; then
    old_pkg_files_details=$(cat "$state_file")
  fi

  if [[ "$current_pkg_files_details" != "$old_pkg_files_details" ]]; then
    echo "Обнаружены изменения для $repo-local в $repo_dir. Запуск инкрементальной индексации..."

    # Создаем временные файлы для сравнения
    current_list=$(mktemp)
    old_list=$(mktemp)
    
    echo "$current_pkg_files_details" > "$current_list"
    echo "$old_pkg_files_details" > "$old_list"
    
    # Находим новые/измененные пакеты
    new_or_changed=$(comm -13 "$old_list" "$current_list" | cut -f1)
    
    # Находим удаленные пакеты
    removed=$(comm -23 "$old_list" "$current_list" | cut -f1)
    
    update_ok=true

    # Удаляем удаленные пакеты из базы
    if [[ -n "$removed" ]] && [[ -f "$db_path" ]]; then
      while IFS= read -r pkg_file; do
        # Извлекаем имя пакета без расширения и версии
        pkg_name=$(echo "$pkg_file" | sed 's/-[^-]*-[^-]*-[^-]*\.pkg\.tar\.zst$//')
        echo "Удаляем пакет $pkg_name из базы $repo-local"
        repo-remove "$db_path" "$pkg_name" 2>/dev/null || true
      done <<< "$removed"
    fi
    
    # Добавляем новые/измененные пакеты
    if [[ -n "$new_or_changed" ]]; then
      echo "Добавляем/обновляем пакеты в $repo-local:"
      echo "$new_or_changed"
      
      # Формируем полные пути к файлам
      pkg_files=()
      while IFS= read -r pkg_file; do
        [[ -n "$pkg_file" ]] && pkg_files+=("$repo_dir/$pkg_file")
      done <<< "$new_or_changed"
      
      if [[ ${#pkg_files[@]} -gt 0 ]]; then
        if ! repo-add "$db_path" "${pkg_files[@]}"; then
          update_ok=false
        fi
      fi
    fi
    
    # Очистка временных файлов
    rm -f "$current_list" "$old_list"

    # Сохраняем новое состояние после успешной индексации
    if [[ "$update_ok" = true ]]; then
      echo "$current_pkg_files_details" > "$state_file"
      echo "Инкрементальная индексация $repo-local успешно завершена."
    else
      echo "Ошибка во время выполнения индексации для $repo-local. Файл состояния не обновлен." >&2
    fi
  else
    echo "Изменений для $repo-local в $repo_dir не обнаружено. Пропуск индексации."
  fi
done
